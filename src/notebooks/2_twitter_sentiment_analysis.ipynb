{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "kS8xG6uHq0ZQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "IN_COLAB = False if os.getenv(\"COLAB_RELEASE_TAG\") is None else True\n",
    "print(IN_COLAB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AWLO4-GLq0ZR"
   },
   "source": [
    "##### Copy project to Colab Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "D1LT_OFs0Sk3"
   },
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "    project_root = \"/content/drive/MyDrive/Colab-Notebooks/LLM/sentiment-analysis\"\n",
    "    data_folder = \"/content/drive/MyDrive/dataset/LLM/sentiment140\"  # os.path.join(project_root, \"data\")\n",
    "    INPUT_FILE_COLAB = \"data/training.1600000.processed.noemoticon.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "CVC2caur0Pw0"
   },
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "    ## --------Mount google drive to Colab --------\n",
    "    import os\n",
    "    import sys\n",
    "    from google.colab import drive\n",
    "\n",
    "    root = \"/content\"\n",
    "    drive.mount(os.path.join(root, \"drive/\"), force_remount=True)\n",
    "\n",
    "    # -------- copy the project code and data----------------\n",
    "    project_tag = (\n",
    "        os.path.basename(os.path.dirname(project_root))\n",
    "        + \"_\"\n",
    "        + os.path.basename(project_root)\n",
    "    )\n",
    "    project_tag\n",
    "    %cd $root\n",
    "    %rm -rfv project\n",
    "\n",
    "    # import the project code to workspace\n",
    "    import os\n",
    "\n",
    "    %cd $root\n",
    "    %rm -rfv project\n",
    "    %mkdir project\n",
    "    !cp -r $project_root/* project\n",
    "    %cd project\n",
    "\n",
    "    #  copy the project data locally\n",
    "    !rm  -r data/\n",
    "    !cp  -r \"$data_folder/\" data/\n",
    "    !ls data\n",
    "\n",
    "    # extract the zip data\n",
    "    !unzip data/*.zip -d data/\n",
    "    !unzip data/*/*.zip -d data/*/\n",
    "\n",
    "    # show the copied data\n",
    "    %ls data/**/**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yHtKY3gy0Zxl"
   },
   "source": [
    "#### input variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "v79255080OTG"
   },
   "outputs": [],
   "source": [
    "INPUT_FILE = \"artifacts/data_ingestion/training.1600000.processed.noemoticon.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "rPA3pklSq0ZY"
   },
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "    INPUT_FILE = INPUT_FILE_COLAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "180f0dd2a95419e4602b5c0229822b0111c826f6",
    "id": "P3p27ui60OTV"
   },
   "outputs": [],
   "source": [
    "# DATASET\n",
    "DATASET_COLUMNS = [\"target\", \"ids\", \"date\", \"flag\", \"user\", \"text\"]\n",
    "DATASET_ENCODING = \"ISO-8859-1\"\n",
    "TRAIN_SIZE = 0.8\n",
    "\n",
    "# TEXT CLENAING\n",
    "TEXT_CLEANING_RE = \"@\\S+|https?:\\S+|http?:\\S|[^A-Za-z0-9]+\"\n",
    "\n",
    "# WORD2VEC\n",
    "W2V_SIZE = 300\n",
    "W2V_WINDOW = 7\n",
    "W2V_EPOCH = 32\n",
    "W2V_MIN_COUNT = 10\n",
    "\n",
    "# KERAS\n",
    "SEQUENCE_LENGTH = 300\n",
    "EPOCHS = 8\n",
    "BATCH_SIZE = 1024\n",
    "\n",
    "# SENTIMENT\n",
    "POSITIVE = \"POSITIVE\"\n",
    "NEGATIVE = \"NEGATIVE\"\n",
    "NEUTRAL = \"NEUTRAL\"\n",
    "SENTIMENT_THRESHOLDS = (0.4, 0.7)\n",
    "\n",
    "# EXPORT\n",
    "KERAS_MODEL = \"models/model.keras\"\n",
    "WORD2VEC_MODEL = \"models/model.w2v\"\n",
    "TOKENIZER_MODEL = \"models/tokenizer.pkl\"\n",
    "ENCODER_MODEL = \"models/encoder.pkl\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### setup the workspace variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "mUC1LA410OTN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/app\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd /app\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"src\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "92b885dd147dac19bd0a33db3cd0da100bd5bc23",
    "id": "IpdllG5T0OTP"
   },
   "source": [
    "#### install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_uuid": "70282bce8b42a51e4d44f2c7d85c4ca9567b0fd4",
    "id": "sBh12fFJ0OTR"
   },
   "outputs": [],
   "source": [
    "# # %%capture\n",
    "# %pip install gensim==4.3.3 #--upgrade\n",
    "# %pip install keras==3.7.0 #--upgrade\n",
    "# %pip install pandas==2.2.3 #--upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yWIsgkThvmgh"
   },
   "source": [
    "# Project: Twitter Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0yHdOMw4u_fc"
   },
   "source": [
    "### load the needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_uuid": "303e72966af732ddef0bd8108a321095314e44af",
    "id": "yHdrhJ0-0OTS"
   },
   "outputs": [],
   "source": [
    "# DataFrame\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import (\n",
    "    Activation,\n",
    "    Dense,\n",
    "    Dropout,\n",
    "    Embedding,\n",
    "    Flatten,\n",
    "    Conv1D,\n",
    "    MaxPooling1D,\n",
    "    LSTM,\n",
    ")\n",
    "from keras import utils\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "# nltk\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "# Word2vec\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Utility\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "from collections import Counter\n",
    "import logging\n",
    "import time\n",
    "import pickle\n",
    "import itertools\n",
    "\n",
    "# Set log\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s : %(levelname)s : %(message)s\", level=logging.INFO\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_uuid": "35e1a89dead5fd160e4c9a024a21d2e569fc89ff",
    "id": "8dASwPxJ0OTT"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1c3beecc618be68480b3d4f0de08d9d863da1dc1",
    "id": "7yF6T9xF0OTW"
   },
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "563b3c44f1092dba0b853747b098e00509098cca",
    "id": "_YLedtL10OTW"
   },
   "source": [
    "### Loaded dataset\n",
    "The loaded datset schema is :\n",
    "* **target**: the polarity of the tweet (0 = negative, 2 = neutral, 4 = positive)\n",
    "* **ids**: The id of the tweet ( 2087)\n",
    "* **date**: the date of the tweet (Sat May 16 23:58:44 UTC 2009)\n",
    "* **flag**: The query (lyx). If there is no query, then this value is NO_QUERY.\n",
    "* **user**: the user that tweeted (robotickilldozr)\n",
    "* **text**: the text of the tweet (Lyx is cool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bba8f91cd70de4f5ea0fb0870ae2029b6e3dcc24",
    "id": "vG7CxZb20OTW"
   },
   "outputs": [],
   "source": [
    "print(\"Open file:\", INPUT_FILE)\n",
    "df = pd.read_csv(INPUT_FILE, encoding=DATASET_ENCODING, names=DATASET_COLUMNS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "936d499c00c4f1648bc16ca9d283c3b39be7fb10",
    "id": "aFSEZt5t0OTX"
   },
   "outputs": [],
   "source": [
    "print(\"Dataset size:\", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7486ed895b813c5246f97b31b6162b0f65ff763b",
    "id": "qZGrVBp10OTX"
   },
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3f9a7bb129e184967b13261fb5d253af451c75c5",
    "id": "daLlzo5I0OTY"
   },
   "source": [
    "### Map target label to String\n",
    "* **0** -> **NEGATIVE**\n",
    "* **2** -> **NEUTRAL**\n",
    "* **4** -> **POSITIVE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "_uuid": "14074b59106cb9550440839e48b832223fc9502f",
    "id": "FlOt77FN0OTY"
   },
   "outputs": [],
   "source": [
    "decode_map = {0: \"NEGATIVE\", 2: \"NEUTRAL\", 4: \"POSITIVE\"}\n",
    "\n",
    "\n",
    "def decode_sentiment(label):\n",
    "    return decode_map[int(label)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4449d473187f647a195a6ac6986b009da32a7f4b",
    "id": "vV4iwJcp0OTZ"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "df.target = df.target.apply(lambda x: decode_sentiment(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "19eb327803192f31cce3512aacb232f4d6b38715",
    "id": "d6j219KQ0OTZ"
   },
   "outputs": [],
   "source": [
    "target_cnt = Counter(df.target)\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.bar(target_cnt.keys(), target_cnt.values())\n",
    "plt.title(\"Dataset labels distribuition\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4329b1573518b03e497213efa7676220734ebb4b",
    "id": "hOK9kGAU0OTa"
   },
   "source": [
    "## Data Cleaning and pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_f1b4dWPSYID"
   },
   "source": [
    "### clean unvalid texts (stemmer language -> english)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "_uuid": "8aeee8b7b9ea11b749c7f91cd4787a7b50ed1a91",
    "id": "edh4YMe-0OTa"
   },
   "outputs": [],
   "source": [
    "stop_words = stopwords.words(\"english\")\n",
    "stemmer = SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "_uuid": "649ebcb97969b9ac4301138783704bb3d7846a49",
    "id": "RnH9e0jn0OTa"
   },
   "outputs": [],
   "source": [
    "def preprocess(text, stem=False):\n",
    "    # Remove link,user and special characters\n",
    "    text = re.sub(TEXT_CLEANING_RE, \" \", str(text).lower()).strip()\n",
    "    tokens = []\n",
    "    for token in text.split():\n",
    "        if token not in stop_words:\n",
    "            if stem:\n",
    "                tokens.append(stemmer.stem(token))\n",
    "            else:\n",
    "                tokens.append(token)\n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f7f3e77ab9291d14687c49e71ba9b2b1e3323432",
    "id": "c1QPYQxD0OTb"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "df.text = df.text.apply(lambda x: preprocess(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f5f9714a8507409bbe780eebf2855a33e8e6ba37",
    "id": "KORKJq4T0OTb"
   },
   "source": [
    "### Split train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d2b1179c968e3f3910c790ecf0c5b2cbb34b0e68",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vXNQ3kfR0OTb",
    "outputId": "1c3a094a-4625-4dcc-f269-22f6afca1f4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN size: 1280000\n",
      "TEST size: 320000\n"
     ]
    }
   ],
   "source": [
    "df_train, df_test = train_test_split(df, test_size=1 - TRAIN_SIZE, random_state=42)\n",
    "print(\"TRAIN size:\", len(df_train))\n",
    "print(\"TEST size:\", len(df_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s6NiS0qbwiDR"
   },
   "source": [
    "## Data Transformtion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f08a28aab2c3d16d8b9681a7d5d07587153a1cd6",
    "id": "5ixH3C2G0OTc"
   },
   "source": [
    "### Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zhVbGdeF8FDl"
   },
   "source": [
    "#### prepare the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2461bf564de1b4414841933d0c1d1bee5f5cc5a6",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u6OjCdND0OTc",
    "outputId": "1b7d3ffa-f565-421d-ebee-98263fc9c29e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.46 s, sys: 844 ms, total: 8.3 s\n",
      "Wall time: 8.44 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "documents = [_text.split() for _text in df_train.text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8e19b9f25801ba86420decc266d2b3e6fb44f1ea",
    "id": "RgM8ECzV0OTc"
   },
   "outputs": [],
   "source": [
    "w2v_model = gensim.models.word2vec.Word2Vec(\n",
    "    vector_size=W2V_SIZE, window=W2V_WINDOW, min_count=W2V_MIN_COUNT, workers=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WMzBvgTRrJiA",
    "outputId": "d815d318-4242-4973-a389-aba8ffd4eff2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- the pretrained model was loadded successfully from the path models/model.w2v\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained Word2Vec model if any.\n",
    "if os.path.exists(WORD2VEC_MODEL):\n",
    "    w2v_model = gensim.models.Word2Vec.load(WORD2VEC_MODEL)\n",
    "    print(\n",
    "        f\"- the pretrained model was loadded successfully from the path {WORD2VEC_MODEL}\"\n",
    "    )\n",
    "else:\n",
    "    print(f\"- no pretrained model was found in path {WORD2VEC_MODEL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "58d655af07653c594bec6bebcfb302a973b0ad9c",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425
    },
    "id": "geRvXBy-0OTd",
    "outputId": "181da209-e3af-4cba-c83b-3ce51da86848",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gensim.models.keyedvectors:sorting after vectors have been allocated is expensive & error-prone\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 30459 is out of bounds for axis 0 with size 30369",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-e314fe26fd45>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mw2v_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36mbuild_vocab\u001b[0;34m(self, corpus_iterable, corpus_file, update, progress_per, keep_raw_vocab, trim_rule, **kwargs)\u001b[0m\n\u001b[1;32m    493\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcorpus_count\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus_total_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_words\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 495\u001b[0;31m         \u001b[0mreport_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_raw_vocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeep_raw_vocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrim_rule\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrim_rule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    496\u001b[0m         \u001b[0mreport_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'memory'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimate_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreport_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'num_retained_words'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36mprepare_vocab\u001b[0;34m(self, update, keep_raw_vocab, trim_rule, min_count, sample, dry_run)\u001b[0m\n\u001b[1;32m    767\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msorted_vocab\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 769\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_by_descending_frequency\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    770\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    771\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36msort_by_descending_frequency\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sorting after vectors have been allocated is expensive & error-prone\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcount_sorted_indexes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    758\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey_to_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_to_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 30459 is out of bounds for axis 0 with size 30369"
     ]
    }
   ],
   "source": [
    "w2v_model.build_vocab(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "72a5628ca81fd4b8983c12d93ae0bf950b86b6ae",
    "id": "Kl3ebz5i0OTd"
   },
   "outputs": [],
   "source": [
    "words = list(w2v_model.wv.index_to_key)\n",
    "vocab_size = len(words)\n",
    "print(\"Vocab size\", vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6X3vlcrI7_KK"
   },
   "source": [
    "#### train the Word2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "68c3e4a5ba07cac3dee67f78ecdd1404c7f83f14",
    "id": "2y3eRGTl0OTe",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "w2v_model.train(documents, total_examples=len(documents), epochs=W2V_EPOCH)\n",
    "\n",
    "# save the trained w2v_model\n",
    "w2v_model.save(WORD2VEC_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "27cc2651c74227115d8bfd8c40e5618048e05edd",
    "id": "m9RsIvIC0OTf"
   },
   "outputs": [],
   "source": [
    "w2v_model.wv.most_similar(\"love\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e13563644468037258598637b49373ca96b9b879",
    "id": "XC2ZkEWc0OTf"
   },
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6852bc709a7cd20173cbeeb218505078f8f37c57",
    "id": "3JLCFaHZ0OTf"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(df_train.text)\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print(\"Total words\", vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "45de439df3015030c71f84c2d170346936a1d68f",
    "id": "OahPw6ab0OTg"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "x_train = pad_sequences(\n",
    "    tokenizer.texts_to_sequences(df_train.text), maxlen=SEQUENCE_LENGTH\n",
    ")\n",
    "x_test = pad_sequences(\n",
    "    tokenizer.texts_to_sequences(df_test.text), maxlen=SEQUENCE_LENGTH\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "03b35903fc6260e190d6928d240ef7432de117fc",
    "id": "fUnbwtmG0OTg"
   },
   "source": [
    "### Label Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "33676e0efa39e97d89bd650b8b4eae933a22fbf0",
    "id": "iw5DU5U10OTg"
   },
   "outputs": [],
   "source": [
    "labels = df_train.target.unique().tolist()\n",
    "labels.append(NEUTRAL)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "04239a9bef76e7922fd86098a5601dfde8ee4665",
    "id": "hoXq2Ew30OTh"
   },
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoder.fit(df_train.target.tolist())\n",
    "\n",
    "y_train = encoder.transform(df_train.target.tolist())\n",
    "y_test = encoder.transform(df_test.target.tolist())\n",
    "\n",
    "y_train = y_train.reshape(-1, 1)\n",
    "y_test = y_test.reshape(-1, 1)\n",
    "\n",
    "print(\"y_train\", y_train.shape)\n",
    "print(\"y_test\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "04299c886911ca135583ab64878f213939a2990c",
    "id": "L9YiFfUk0OTh"
   },
   "outputs": [],
   "source": [
    "print(\"x_train\", x_train.shape)\n",
    "print(\"y_train\", y_train.shape)\n",
    "print()\n",
    "print(\"x_test\", x_test.shape)\n",
    "print(\"y_test\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "232533fb27b7be99d9b8c2f8fb22c9c6bf121a6f",
    "id": "PdfxwCZG0OTh"
   },
   "outputs": [],
   "source": [
    "y_train[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4gMOc5yqwym_",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aNi7HH50w8Y-"
   },
   "source": [
    "### Build embeddings layer and classification model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "233c0ea94055a03e2e7df3e2a13d036ec963484f",
    "id": "x9NWd8wd0OTh"
   },
   "source": [
    "#### Embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9ab488374b59e3f30f8b1ea92767d853c4846bac",
    "id": "IoLZ_JpS0OTq"
   },
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((vocab_size, W2V_SIZE))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if word in w2v_model.wv:\n",
    "        embedding_matrix[i] = w2v_model.wv[word]\n",
    "print(embedding_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "833279d91e4286065968237fb5f2a0c2dd4d246c",
    "id": "WpwPJNqK0OTq"
   },
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(\n",
    "    vocab_size,\n",
    "    W2V_SIZE,\n",
    "    weights=[embedding_matrix],\n",
    "    input_length=SEQUENCE_LENGTH,\n",
    "    trainable=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b299ef78f94c2085942c993a2d58753a7476305a",
    "id": "jfcPD83T0OTr"
   },
   "source": [
    "#### Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e775ef4f1b74e6412457181383c39f2df554ef3f",
    "id": "Q7SO2ehy0OTr"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(embedding_layer)\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zSqH6fUwxNfu"
   },
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "28d22eafd0c7d798dcf3d742bc92fb8577939e6c",
    "id": "Q8c6qQcP0OTr"
   },
   "source": [
    "#### Compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1331e08d590bb2aa2033706c8faca217afc0f1c3",
    "id": "4lPrcNKM0OTs"
   },
   "outputs": [],
   "source": [
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c7733127cb8b380e0c807268903bf4d03ef92542",
    "id": "wyEDJfyW0OTs"
   },
   "source": [
    "#### Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a688df590386f5748da6fe00b01904fe6c71619e",
    "id": "xm9pBRhK0OTs"
   },
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    ReduceLROnPlateau(monitor=\"val_loss\", patience=5, cooldown=0),\n",
    "    EarlyStopping(monitor=\"val_accuracy\", min_delta=1e-4, mode=\"max\", patience=5),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8d0873633dd49179c8cae17377641b97d323ef3b",
    "id": "6_5VXegg0OTs"
   },
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HbaMbJPZ7eGz"
   },
   "outputs": [],
   "source": [
    "# Load pre-trained classification model if any.\n",
    "if os.path.exists(KERAS_MODEL):\n",
    "    model = tf.keras.models.load_model(KERAS_MODEL)\n",
    "    print(\n",
    "        f\"- the pretrained model was loadded successfully from the path {WORD2VEC_MODEL}\"\n",
    "    )\n",
    "else:\n",
    "    print(f\"- no pretrained model was found in path {KERAS_MODEL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2b659d390c6577dc5cdb6b6297934279b4e801d5",
    "id": "ikZT_IbY0OTt"
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# history = model.fit(x_train, y_train,\n",
    "#                     batch_size=BATCH_SIZE,\n",
    "#                     epochs=1,\n",
    "#                     validation_split=0.1,\n",
    "#                     verbose=1,\n",
    "#                     callbacks=callbacks)\n",
    "\n",
    "# # save trained model\n",
    "# model.save(KERAS_MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4f014c32f3833db282e1a075c526604f34e3158c",
    "id": "MtgiZhxo0OT1"
   },
   "source": [
    "#### Save trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZeEpwGNM3COQ"
   },
   "outputs": [],
   "source": [
    "%cd $root/project\n",
    "%mkdir  models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3b2b3ad5b592977b404acfa1c9ad303a62837255",
    "id": "74KUYfRI0OT1"
   },
   "outputs": [],
   "source": [
    "# model.save(KERAS_MODEL)\n",
    "# w2v_model.save(WORD2VEC_MODEL)\n",
    "# pickle.dump(tokenizer, open(TOKENIZER_MODEL, \"wb\"), protocol=0)\n",
    "# pickle.dump(encoder, open(ENCODER_MODEL, \"wb\"), protocol=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "267258196d96796ac69a7b8c466314bcf5d6ee42",
    "id": "6uFGMac20OTt"
   },
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3TWp1seox0wQ"
   },
   "source": [
    "#### Training performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "98ecd8f1b8b74594c3ea775dd68a094e92458022",
    "id": "wRp8XB270OTt"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# score = model.evaluate(x_test, y_test, batch_size=BATCH_SIZE)\n",
    "# print(\"\\nACCURACY:\",score[1])\n",
    "# print(\"LOSS:\",score[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "40c72cd1e9d6c4fd799cbba7c813765ac4039dfc",
    "id": "HocAW2vi0OTu"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    acc = history.history[\"accuracy\"]\n",
    "    val_acc = history.history[\"val_accuracy\"]\n",
    "    loss = history.history[\"loss\"]\n",
    "    val_loss = history.history[\"val_loss\"]\n",
    "\n",
    "    epochs = range(len(acc))\n",
    "\n",
    "    plt.plot(epochs, acc, \"b\", label=\"Training acc\")\n",
    "    plt.plot(epochs, val_acc, \"r\", label=\"Validation acc\")\n",
    "    plt.title(\"Training and validation accuracy\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.figure()\n",
    "\n",
    "    plt.plot(epochs, loss, \"b\", label=\"Training loss\")\n",
    "    plt.plot(epochs, val_loss, \"r\", label=\"Validation loss\")\n",
    "    plt.title(\"Training and validation loss\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n",
    "except Exception as e:\n",
    "    print(\n",
    "        f\"\\n - The training performance is not avaialble!!\\\n",
    "  \\n because {e}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3ee72e47f84b6dbc32e02a783de5ec1661f157e1",
    "id": "S207Tv7H0OTx"
   },
   "source": [
    "#### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0e920173eb05f04aecdd735bc5dff0f5be5f8d15",
    "id": "8eMZ70pv0OTx"
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# y_pred_1d = []\n",
    "# y_test_1d = list(df_test.target)\n",
    "# scores = model.predict(x_test, verbose=1, batch_size=8000)\n",
    "# y_pred_1d = [decode_sentiment(score, include_neutral=False) for score in scores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b3575191bb425ab871f3f41e83812ee84bb7e595",
    "id": "lS-cZgdB0OTy"
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes, title=\"Confusion matrix\", cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "\n",
    "    cm = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    plt.imshow(cm, interpolation=\"nearest\", cmap=cmap)\n",
    "    plt.title(title, fontsize=30)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=90, fontsize=22)\n",
    "    plt.yticks(tick_marks, classes, fontsize=22)\n",
    "\n",
    "    fmt = \".2f\"\n",
    "    thresh = cm.max() / 2.0\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(\n",
    "            j,\n",
    "            i,\n",
    "            format(cm[i, j], fmt),\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"white\" if cm[i, j] > thresh else \"black\",\n",
    "        )\n",
    "\n",
    "    plt.ylabel(\"True label\", fontsize=25)\n",
    "    plt.xlabel(\"Predicted label\", fontsize=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a57dc6f6211c144491a70f533225edfa95a2dc66",
    "id": "rmY7H48P0OTy"
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# cnf_matrix = confusion_matrix(y_test_1d, y_pred_1d)\n",
    "# plt.figure(figsize=(12,12))\n",
    "# plot_confusion_matrix(cnf_matrix, classes=df_train.target.unique(), title=\"Confusion matrix\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e23b957348dcc084249d3cc7538b972da471c2cd",
    "id": "zOthYg-N0OTy"
   },
   "source": [
    "#### Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a7fe05b7caa1c984ff1deb0be2f7c6bc043df9f5",
    "id": "MTvgtTlx0OTz"
   },
   "outputs": [],
   "source": [
    "# print(classification_report(y_test_1d, y_pred_1d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4eb300f0c6693a618587c7dcf32f77f5416cbfb9",
    "id": "DjR65y8F0OT0"
   },
   "source": [
    "#### Accuracy Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5cf76e6e09f8a60ed25947932b94c772eda44d23",
    "id": "AnB8op8x0OT0"
   },
   "outputs": [],
   "source": [
    "# accuracy_score(y_test_1d, y_pred_1d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qjUbfTzE2plP"
   },
   "source": [
    "### Export the trained model to Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5EGatV5Y2u_K",
    "outputId": "74ee7305-2573-430e-be1f-d83715b28ea9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/project\n",
      "mkdir: invalid option -- 'f'\n",
      "Try 'mkdir --help' for more information.\n",
      "'models/model.h5' -> '/content/drive/MyDrive/Colab-Notebooks/LLM/sentiment-analysis/models/model.h5'\n",
      "'models/model.w2v' -> '/content/drive/MyDrive/Colab-Notebooks/LLM/sentiment-analysis/models/model.w2v'\n",
      "'models/tokenizer.pkl' -> '/content/drive/MyDrive/Colab-Notebooks/LLM/sentiment-analysis/models/tokenizer.pkl'\n",
      "'models/encoder.pkl' -> '/content/drive/MyDrive/Colab-Notebooks/LLM/sentiment-analysis/models/encoder.pkl'\n",
      "'models/model.keras' -> '/content/drive/MyDrive/Colab-Notebooks/LLM/sentiment-analysis/models/model.keras'\n",
      "^C\n",
      "cp: cannot stat 'artifacts/models': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "if IN_COLAB:\n",
    "    %cd $root/project\n",
    "    %mkdir -fp $project_root/models\n",
    "    %cp -rfv models $project_root/\n",
    "    %cp -rfv artifacts/models $project_root/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "id": "eXrptWRqq0Zz"
   },
   "outputs": [],
   "source": [
    "# ## Exit colab\n",
    "# if IN_COLAB:\n",
    "# \tfrom google.colab import runtime\n",
    "# \truntime.unassign()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6bdfc0f6a6af5bebc0271d83dd7432c91001409b",
    "id": "9nT3E5pL0OTu"
   },
   "source": [
    "## Model Inference and Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ipywidgets\n",
      "  Downloading ipywidgets-8.1.5-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: comm>=0.1.3 in /usr/local/lib/python3.11/site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.11/site-packages (from ipywidgets) (8.30.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.11/site-packages (from ipywidgets) (5.14.3)\n",
      "Collecting widgetsnbextension~=4.0.12 (from ipywidgets)\n",
      "  Downloading widgetsnbextension-4.0.13-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting jupyterlab-widgets~=3.0.12 (from ipywidgets)\n",
      "  Downloading jupyterlab_widgets-3.0.13-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /usr/local/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.48)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /usr/local/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (2.18.0)\n",
      "Requirement already satisfied: stack_data in /usr/local/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: typing_extensions>=4.6 in /usr/local/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (4.12.2)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in /usr/local/lib/python3.11/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /usr/local/lib/python3.11/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in /usr/local/lib/python3.11/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "Downloading ipywidgets-8.1.5-py3-none-any.whl (139 kB)\n",
      "Downloading jupyterlab_widgets-3.0.13-py3-none-any.whl (214 kB)\n",
      "Downloading widgetsnbextension-4.0.13-py3-none-any.whl (2.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "Installing collected packages: widgetsnbextension, jupyterlab-widgets, ipywidgets\n",
      "Successfully installed ipywidgets-8.1.5 jupyterlab-widgets-3.0.13 widgetsnbextension-4.0.13\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install ipywidgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vr7D6FmA1jRq"
   },
   "source": [
    "#### load the trained tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IlzCz5sf1j-Y",
    "outputId": "d4007693-56de-4450-c678-2ec5ca3f9819"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-14 21:32:21.832367: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1734211943.010495      21 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1734211943.221657      21 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-14 21:32:25.522180: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1129], [475], [499], [499], []]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Load tokenizer from the pickle file\n",
    "with open(TOKENIZER_MODEL, \"rb\") as file:\n",
    "    loaded_tokenizer = pickle.load(file)\n",
    "\n",
    "# Test loaded tokenizer\n",
    "text = \"Hello\"\n",
    "tokenized_text = loaded_tokenizer.texts_to_sequences(text)\n",
    "print(tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PkHap_2P154j",
    "outputId": "0387f577-0375-4c64-9832-8d6c91085ea7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- example_labels = [0, 1]      \n",
      "- encoded_classes = ['NEGATIVE' 'POSITIVE']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator LabelEncoder from version 1.5.2 when using version 1.6.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load tokenizer from the pickle file\n",
    "with open(ENCODER_MODEL, \"rb\") as file:\n",
    "    loaded_encoder = pickle.load(file)\n",
    "\n",
    "# Test loaded tokenizer\n",
    "example_labels = [k for k in range(len(loaded_encoder.classes_))]\n",
    "encoded_labels = loaded_encoder.inverse_transform(example_labels)\n",
    "\n",
    "assert set(loaded_encoder.classes_) == set(encoded_labels)\n",
    "print(\n",
    "    f\"- example_labels = {example_labels}\\\n",
    "      \\n- encoded_classes = {encoded_labels}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xGTI2X49ykpz"
   },
   "source": [
    "#### load the trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "paa77juk0AHb"
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "\n",
    "w2v_model = gensim.models.Word2Vec.load(WORD2VEC_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yNZpxOko4iLi",
    "outputId": "424e2a9e-2911-4646-f99f-d3138e109a1a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-14 21:32:58.792620: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2024-12-14 21:32:58.957983: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 348502800 exceeds 10% of free system memory.\n",
      "2024-12-14 21:32:59.355470: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 348502800 exceeds 10% of free system memory.\n",
      "2024-12-14 21:32:59.609171: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 348502800 exceeds 10% of free system memory.\n",
      "2024-12-14 21:33:07.233856: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 348502800 exceeds 10% of free system memory.\n",
      "/usr/local/lib/python3.11/site-packages/keras/src/saving/saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'adam', because it has 12 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "loaded_clf_model = tf.keras.models.load_model(KERAS_MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fwv038Ws5TQp"
   },
   "source": [
    "#### prediction functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.11/site-packages (8.1.5)\n",
      "Requirement already satisfied: comm>=0.1.3 in /usr/local/lib/python3.11/site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.11/site-packages (from ipywidgets) (8.30.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.11/site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.12 in /usr/local/lib/python3.11/site-packages (from ipywidgets) (4.0.13)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in /usr/local/lib/python3.11/site-packages (from ipywidgets) (3.0.13)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /usr/local/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.48)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /usr/local/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (2.18.0)\n",
      "Requirement already satisfied: stack_data in /usr/local/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: typing_extensions>=4.6 in /usr/local/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (4.12.2)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in /usr/local/lib/python3.11/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /usr/local/lib/python3.11/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in /usr/local/lib/python3.11/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "_uuid": "f0b0fa3d4b1bb14b3f5e3d169a369f3ebef29ae1",
    "id": "BLUcHhwF0OTv"
   },
   "outputs": [],
   "source": [
    "# decode_map = {0: \"NEGATIVE\", 2: \"NEUTRAL\", 4: \"POSITIVE\"}\n",
    "# def decode_sentiment(label):\n",
    "#     return decode_map[int(label)]\n",
    "import ipywidgets as widgets\n",
    "\n",
    "\n",
    "def decode_sentiment(score, include_neutral=True):\n",
    "    if include_neutral:\n",
    "        label = NEUTRAL\n",
    "        if score <= SENTIMENT_THRESHOLDS[0]:\n",
    "            label = NEGATIVE\n",
    "        elif score >= SENTIMENT_THRESHOLDS[1]:\n",
    "            label = POSITIVE\n",
    "\n",
    "        return label\n",
    "    else:\n",
    "        return NEGATIVE if score < 0.5 else POSITIVE\n",
    "\n",
    "\n",
    "def show_sentiment_thermometer(label, score):\n",
    "    if score < 0.5:\n",
    "        color = {\"bar_color\": \"#cc0000\"}\n",
    "    elif score == 0.5:\n",
    "        color = {\"bar_color\": \"#555753\"}\n",
    "    else:\n",
    "        color = {\"bar_color\": \"#00ff00\"}\n",
    "\n",
    "    thermometer = widgets.FloatProgress(\n",
    "        value=score,\n",
    "        min=0,\n",
    "        max=1.0,\n",
    "        description=label,\n",
    "        bar_style=\"info\",\n",
    "        style=color,\n",
    "        orientation=\"horizontal\",\n",
    "    )\n",
    "\n",
    "    display(thermometer)\n",
    "\n",
    "    return thermometer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "_uuid": "ed4086d651f2f8cbed11d3c909a8873607d29a06",
    "id": "BGA9wrWy0OTv"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "\n",
    "def predict(text, tokenizer, model, include_neutral=True):\n",
    "    import time\n",
    "\n",
    "    start_at = time.time()\n",
    "    # clean and preprocess the input text\n",
    "    text = (lambda x: preprocess(x))(text)\n",
    "\n",
    "    # Tokenize text\n",
    "    x_test = pad_sequences(tokenizer.texts_to_sequences([text]), maxlen=SEQUENCE_LENGTH)\n",
    "    # Predict\n",
    "    score = model.predict([x_test])[0]\n",
    "    score = np.squeeze(score)\n",
    "    # Decode sentiment\n",
    "    label = decode_sentiment(score, include_neutral=include_neutral)\n",
    "\n",
    "    # print the predictions\n",
    "    print(f\"\\n- processed text : {text}\")\n",
    "    print(f\"\\n- predicted sentiment : {label} (score={100*score:.1f} %)\")\n",
    "    # show thermometer\n",
    "    show_sentiment_thermometer(label, score)\n",
    "\n",
    "    # get results\n",
    "    result = {\n",
    "        \"label\": label,\n",
    "        \"score\": float(score),\n",
    "        \"elapsed_time\": time.time() - start_at,\n",
    "    }\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aRujwlyXyXVe"
   },
   "source": [
    "#### prediction examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "_uuid": "ca38b1e6c9b5acfed7467de2cf02a78333108872",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139,
     "referenced_widgets": [
      "36551f8be8224c77b37e10099b3be61b",
      "5a2a377a20ad4ebdbda152e41f7ecd12",
      "d4aa58ae73f34a01adeb5ec6d3a69555"
     ]
    },
    "id": "CpsR8nXW0OTv",
    "outputId": "77283556-90c6-4de8-b13c-5529af1d5b0a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step\n",
      "\n",
      "- processed text : love latest roky music\n",
      "\n",
      "- predicted sentiment : POSITIVE (score=98.8 %)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25a0f40938354c889db74b56f59e911b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.9880579710006714, bar_style='info', description='POSITIVE', max=1.0, style=ProgressStyle…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = predict(\"I love the latest @RoKy music\", loaded_tokenizer, loaded_clf_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "_uuid": "0e5fe647533be0148850de349fea6ef6f71303d1",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139,
     "referenced_widgets": [
      "ef45692e7475432aa4a592e5c98b1b81",
      "8748ebdddc2e4b91ad07ba95fa1365b9",
      "a3020eb8cf6a466dba5d09dca1bd4356"
     ]
    },
    "id": "QDT07SdP0OTw",
    "outputId": "8d55b00e-cdac-4df0-f0cc-c93f873b09eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step\n",
      "\n",
      "- processed text : hate rain\n",
      "\n",
      "- predicted sentiment : NEGATIVE (score=1.2 %)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2b0c2ff09a04d9ea3473651778e6c1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.011537362821400166, bar_style='info', description='NEGATIVE', max=1.0, style=ProgressSty…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = predict(\"I hate the rain\", loaded_tokenizer, loaded_clf_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "_uuid": "37064dffcc8920d34ccd54fac7c8b50e583a8269",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139,
     "referenced_widgets": [
      "11ed11f99bcf442da88b6915edcdfe84",
      "adcebac5487349ee91fbffeee7b4d942",
      "c31b40d5735440e5bf9bc61daf6fc264"
     ]
    },
    "id": "cOw-ZL140OTw",
    "outputId": "f8575d02-e4f8-43c3-cf8b-54d47a11ed3c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step\n",
      "\n",
      "- processed text : know\n",
      "\n",
      "- predicted sentiment : NEGATIVE (score=38.4 %)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40bfb950cb2f4f71b9ed22a0ec53065f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.38427892327308655, bar_style='info', description='NEGATIVE', max=1.0, style=ProgressStyl…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = predict(\"i don't know what i'm doing\", loaded_tokenizer, loaded_clf_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139,
     "referenced_widgets": [
      "5d2f3131f0344bdfbf9f3c884a2b5289",
      "d5d9b07d27a645989bc0e004b49d274a",
      "81021b72bbf94824866b7da6167d2272"
     ]
    },
    "id": "qk03v6VhiMIX",
    "outputId": "d83673e2-42bf-4ad3-bf93-20aa92563e2d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step\n",
      "\n",
      "- processed text : neutral\n",
      "\n",
      "- predicted sentiment : POSITIVE (score=76.3 %)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a44265b3b7b4ea1a5cfb89628807b08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.7627895474433899, bar_style='info', description='POSITIVE', max=1.0, style=ProgressStyle…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = predict(\"i am neutral\", loaded_tokenizer, loaded_clf_model)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "11ed11f99bcf442da88b6915edcdfe84": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "NEGATIVE",
      "description_tooltip": null,
      "layout": "IPY_MODEL_adcebac5487349ee91fbffeee7b4d942",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c31b40d5735440e5bf9bc61daf6fc264",
      "value": 0.38427892327308655
     }
    },
    "36551f8be8224c77b37e10099b3be61b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "POSITIVE",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5a2a377a20ad4ebdbda152e41f7ecd12",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d4aa58ae73f34a01adeb5ec6d3a69555",
      "value": 0.9880579710006714
     }
    },
    "5a2a377a20ad4ebdbda152e41f7ecd12": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5d2f3131f0344bdfbf9f3c884a2b5289": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "POSITIVE",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d5d9b07d27a645989bc0e004b49d274a",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_81021b72bbf94824866b7da6167d2272",
      "value": 0.7627895474433899
     }
    },
    "81021b72bbf94824866b7da6167d2272": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": "#00ff00",
      "description_width": ""
     }
    },
    "8748ebdddc2e4b91ad07ba95fa1365b9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a3020eb8cf6a466dba5d09dca1bd4356": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": "#cc0000",
      "description_width": ""
     }
    },
    "adcebac5487349ee91fbffeee7b4d942": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c31b40d5735440e5bf9bc61daf6fc264": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": "#cc0000",
      "description_width": ""
     }
    },
    "d4aa58ae73f34a01adeb5ec6d3a69555": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": "#00ff00",
      "description_width": ""
     }
    },
    "d5d9b07d27a645989bc0e004b49d274a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ef45692e7475432aa4a592e5c98b1b81": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "NEGATIVE",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8748ebdddc2e4b91ad07ba95fa1365b9",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a3020eb8cf6a466dba5d09dca1bd4356",
      "value": 0.011537362821400166
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
